{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb264edc",
   "metadata": {},
   "source": [
    "**DATA LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b7c168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867244   \n",
      "1           1   2020-06-21 12:14:33  3573030041201292   \n",
      "2           2   2020-06-21 12:14:53  3598215285024754   \n",
      "3           3   2020-06-21 12:15:15  3591919803438423   \n",
      "4           4   2020-06-21 12:15:17  3526826139003047   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street  ...      lat      long  \\\n",
      "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
      "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
      "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
      "\n",
      "   city_pop                     job         dob  \\\n",
      "0    333497     Mechanical engineer  1968-03-19   \n",
      "1       302  Sales professional, IT  1990-01-17   \n",
      "2     34496       Librarian, public  1970-10-21   \n",
      "3     54767            Set designer  1987-07-25   \n",
      "4      1126      Furniture designer  1955-07-06   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             555719 non-null  int64  \n",
      " 1   trans_date_trans_time  555719 non-null  object \n",
      " 2   cc_num                 555719 non-null  int64  \n",
      " 3   merchant               555719 non-null  object \n",
      " 4   category               555719 non-null  object \n",
      " 5   amt                    555719 non-null  float64\n",
      " 6   first                  555719 non-null  object \n",
      " 7   last                   555719 non-null  object \n",
      " 8   gender                 555719 non-null  object \n",
      " 9   street                 555719 non-null  object \n",
      " 10  city                   555719 non-null  object \n",
      " 11  state                  555719 non-null  object \n",
      " 12  zip                    555719 non-null  int64  \n",
      " 13  lat                    555719 non-null  float64\n",
      " 14  long                   555719 non-null  float64\n",
      " 15  city_pop               555719 non-null  int64  \n",
      " 16  job                    555719 non-null  object \n",
      " 17  dob                    555719 non-null  object \n",
      " 18  trans_num              555719 non-null  object \n",
      " 19  unix_time              555719 non-null  int64  \n",
      " 20  merch_lat              555719 non-null  float64\n",
      " 21  merch_long             555719 non-null  float64\n",
      " 22  is_fraud               555719 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 97.5+ MB\n",
      "None\n",
      "\n",
      "Class Distribution:\n",
      "is_fraud\n",
      "0    99.614014\n",
      "1     0.385986\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    df=pd.read_csv('../data/fraudTest.csv')\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'fraudTest.csv' not found. Make sure the file is in the '/data' folder.\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['is_fraud'].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49370645",
   "metadata": {},
   "source": [
    "**FEATURE ENGINEERING AND DATA BALANCING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75e09b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\AppData\\Local\\Temp\\ipykernel_16792\\3787367430.py:26: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  rolling_freq = df_indexed.groupby('cc_num')['cc_num'].rolling('3H').count().rename('transaction_frequency_3hr')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info after Preprocessing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 555767 entries, 617 to 555203\n",
      "Columns: 501 entries, Unnamed: 0 to job_Writer\n",
      "dtypes: bool(478), datetime64[ns](1), float64(7), int64(5), object(10)\n",
      "memory usage: 355.1+ MB\n",
      "\n",
      "Final DataFrame Head:\n",
      "      Unnamed: 0 trans_date_trans_time           cc_num  \\\n",
      "617          617   2020-06-21 15:41:32  180011453250192   \n",
      "923          923   2020-06-21 17:33:11  180011453250192   \n",
      "1065        1065   2020-06-21 18:15:55  180011453250192   \n",
      "1491        1491   2020-06-21 20:49:21  180011453250192   \n",
      "1692        1692   2020-06-21 22:08:56  180011453250192   \n",
      "\n",
      "                                merchant     category  Amount  first  last  \\\n",
      "617                      fraud_Brown Inc    kids_pets   42.32  Craig  Dunn   \n",
      "923   fraud_McDermott, Osinski and Morar         home   60.11  Craig  Dunn   \n",
      "1065                    fraud_Turner LLC       travel  549.72  Craig  Dunn   \n",
      "1491              fraud_Jakubowski Group  food_dining   58.76  Craig  Dunn   \n",
      "1692                fraud_Weber and Sons  food_dining   66.89  Craig  Dunn   \n",
      "\n",
      "                     street        city  ... job_Video editor  \\\n",
      "617   721 Jacqueline Brooks  New Boston  ...            False   \n",
      "923   721 Jacqueline Brooks  New Boston  ...            False   \n",
      "1065  721 Jacqueline Brooks  New Boston  ...            False   \n",
      "1491  721 Jacqueline Brooks  New Boston  ...            False   \n",
      "1692  721 Jacqueline Brooks  New Boston  ...            False   \n",
      "\n",
      "      job_Visual merchandiser  job_Volunteer coordinator  job_Warden/ranger  \\\n",
      "617                     False                      False              False   \n",
      "923                     False                      False              False   \n",
      "1065                    False                      False              False   \n",
      "1491                    False                      False              False   \n",
      "1692                    False                      False              False   \n",
      "\n",
      "      job_Waste management officer job_Water engineer  \\\n",
      "617                          False              False   \n",
      "923                          False              False   \n",
      "1065                         False              False   \n",
      "1491                         False              False   \n",
      "1692                         False              False   \n",
      "\n",
      "     job_Water quality scientist  job_Web designer  job_Wellsite geologist  \\\n",
      "617                        False             False                   False   \n",
      "923                        False             False                   False   \n",
      "1065                       False             False                   False   \n",
      "1491                       False             False                   False   \n",
      "1692                       False             False                   False   \n",
      "\n",
      "      job_Writer  \n",
      "617        False  \n",
      "923        False  \n",
      "1065       False  \n",
      "1491       False  \n",
      "1692       False  \n",
      "\n",
      "[5 rows x 501 columns]\n",
      "\n",
      "Original training dataset shape Counter({0: 387535, 1: 1501})\n",
      "Resampled training dataset shape Counter({0: 387535, 1: 387535})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Preprocessing and Feature Engineering ---\n",
    "# Assuming 'df' is your initial DataFrame\n",
    "\n",
    "# Clean up column names by stripping leading/trailing spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df.rename(columns={'amt':'Amount'}, inplace=True)\n",
    "df['cc_num'] = df['cc_num'].astype(str)\n",
    "\n",
    "# Sort for time-based calculations\n",
    "df.sort_values(by=['cc_num', 'trans_date_trans_time'], inplace=True)\n",
    "\n",
    "# Feature: Time since last transaction\n",
    "df['time_since_last_transaction'] = df.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds() / 60\n",
    "df['time_since_last_transaction'].fillna(0, inplace=True) # Fill NaNs for first transactions\n",
    "\n",
    "# Feature: Rolling transaction frequency (Corrected Method)\n",
    "# Temporarily set index for rolling calculation\n",
    "df_indexed = df.set_index('trans_date_trans_time')\n",
    "# Calculate rolling count and merge it back\n",
    "rolling_freq = df_indexed.groupby('cc_num')['cc_num'].rolling('3H').count().rename('transaction_frequency_3hr')\n",
    "df = df.merge(rolling_freq, left_on=['cc_num', 'trans_date_trans_time'], right_index=True, how='left')\n",
    "\n",
    "# Categorical encoding\n",
    "df = pd.get_dummies(df, columns=['gender', 'job'], drop_first=True)\n",
    "\n",
    "print(\"DataFrame Info after Preprocessing:\")\n",
    "df.info()\n",
    "print(\"\\nFinal DataFrame Head:\")\n",
    "print(df.head())\n",
    "\n",
    "# Now drop columns that are no longer needed\n",
    "df.drop(columns=['trans_date_trans_time', 'merchant', 'cc_num'], inplace=True)\n",
    "\n",
    "# Drop all non-numeric columns (object dtype) before modeling\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "X = X.select_dtypes(include=[np.number, 'bool']) # Keep only numeric and boolean columns\n",
    "y = df['is_fraud']\n",
    "\n",
    "# --- 2. Data Splitting (BEFORE SMOTE) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# --- 3. Apply SMOTE only on the Training Data ---\n",
    "print('\\nOriginal training dataset shape %s' % Counter(y_train))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled training dataset shape %s' % Counter(y_train_res))\n",
    "\n",
    "# Now you're ready to train your model on (X_train_res, y_train_res)\n",
    "# And evaluate it on the untouched (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83012b",
   "metadata": {},
   "source": [
    "**TRAINING AND TESTING MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3ca9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model performance on the test set...\n",
      "\n",
      "--- Logistic Regression Results ---\n",
      "F1-score: 0.10884353741496598\n",
      "AUC-ROC: 0.8552949518674395\n",
      "Confusion Matrix:\n",
      " [[158252   7835]\n",
      " [   156    488]]\n",
      "\n",
      "--- Random Forest Results ---\n",
      "F1-score: 0.6368330464716007\n",
      "AUC-ROC: 0.7868215311237577\n",
      "Confusion Matrix:\n",
      " [[165939    148]\n",
      " [   274    370]]\n",
      "\n",
      "--- Voting Classifier Results ---\n",
      "F1-score: 0.2903225806451613\n",
      "AUC-ROC: 0.8569959237482623\n",
      "Confusion Matrix:\n",
      " [[163975   2112]\n",
      " [   176    468]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 1. Model Training ---\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "# Individual models\n",
    "lr_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Voting Classifier (combines both models)\n",
    "# We'll use 'soft' voting to leverage the probability predictions\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('lr', lr_model), ('rf', rf_model)],\n",
    "    voting='soft',  # Use soft voting for better performance\n",
    "    n_jobs=-1       # Use all available CPU cores for faster training\n",
    ")\n",
    "\n",
    "# Train all models\n",
    "lr_model.fit(X_train_res, y_train_res)\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "voting_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- 2. Model Prediction and Evaluation ---\n",
    "print(\"\\nEvaluating model performance on the test set...\")\n",
    "\n",
    "# Make predictions on the original, untouched test set\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "voting_pred = voting_model.predict(X_test)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"\\n--- Logistic Regression Results ---\")\n",
    "print(\"F1-score:\", f1_score(y_test, lr_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, lr_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, lr_pred))\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\n--- Random Forest Results ---\")\n",
    "print(\"F1-score:\", f1_score(y_test, rf_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, rf_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "# Evaluate Voting Classifier\n",
    "print(\"\\n--- Voting Classifier Results ---\")\n",
    "print(\"F1-score:\", f1_score(y_test, voting_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, voting_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, voting_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701fcccd",
   "metadata": {},
   "source": [
    "**BEST THRESHOLD PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1582e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal F1-score for Logistic Regression: 0.2352 at threshold: 0.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Get the probability predictions for the fraudulent class (1)\n",
    "lr_probs = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create a list of possible thresholds to test\n",
    "thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Loop through each threshold and find the best one\n",
    "for threshold in thresholds:\n",
    "    # Convert probabilities to a binary prediction based on the new threshold\n",
    "    y_pred_threshold = (lr_probs >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate the F1-score for this threshold\n",
    "    f1 = f1_score(y_test, y_pred_threshold)\n",
    "    \n",
    "    # If this F1-score is the best we've seen, save it\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        \n",
    "print(f\"Optimal F1-score for Logistic Regression: {best_f1:.4f} at threshold: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d4de8",
   "metadata": {},
   "source": [
    "**HYPERTUNING LOGISTIC REGRESSION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd3979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV for Logistic Regression with a smaller grid...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "3 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n",
      "    values = self._values\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1131, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "                                          ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12691, in values\n",
      "    return self._mgr.as_array()\n",
      "           ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1713, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1746, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 2.26 GiB for an array with shape (489, 620056) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.94857272 0.86751976]\n",
      "  warnings.warn(\n",
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV complete.\n",
      "Best Hyperparameters for LR: {'C': 1, 'penalty': 'l1'}\n",
      "Best F1-score from LR Grid Search: 0.9485727222369041\n",
      "\n",
      "--- Fine-Tuned Logistic Regression Results ---\n",
      "F1-score: 0.12684599156118143\n",
      "AUC-ROC: 0.8540025765513076\n",
      "Confusion Matrix:\n",
      " [[159628   6459]\n",
      " [   163    481]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Define a much smaller, more focused grid for faster results\n",
    "param_grid = {\n",
    "    'C': [0.1, 1],  # Test two key values for regularization strength\n",
    "    'penalty': ['l1', 'l2']   # Test both L1 and L2 penalties\n",
    "}\n",
    "\n",
    "# Create a Logistic Regression classifier instance\n",
    "lr_model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "\n",
    "# Set up GridSearchCV with the Logistic Regression model and the parameter grid\n",
    "grid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='f1', n_jobs=6, verbose=1)\n",
    "\n",
    "# Fit the grid search to your resampled training data\n",
    "print(\"Starting GridSearchCV for Logistic Regression with a smaller grid...\")\n",
    "grid_search_lr.fit(X_train_res, y_train_res)\n",
    "print(\"GridSearchCV complete.\")\n",
    "\n",
    "# Print the best hyperparameters and the corresponding F1-score\n",
    "print(f\"Best Hyperparameters for LR: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best F1-score from LR Grid Search: {grid_search_lr.best_score_}\")\n",
    "\n",
    "# Get the best model\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the untouched test set\n",
    "best_lr_pred = best_lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final, fine-tuned model\n",
    "print(\"\\n--- Fine-Tuned Logistic Regression Results ---\")\n",
    "print(\"F1-score:\", f1_score(y_test, best_lr_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, best_lr_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, best_lr_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
